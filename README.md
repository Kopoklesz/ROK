# üéÆ ROK RL Agent - Rise of Kingdoms Reinforcement Learning Bot

Mesters√©ges intelligencia agent, amely **meger≈ës√≠t√©ses tanul√°ssal** (Deep Q-Learning) tanul meg Rise of Kingdoms j√°t√©kot j√°tszani.

---

## üìã Tartalomjegyz√©k

- [Jellemz≈ëk](#-jellemz≈ëk)
- [Telep√≠t√©s](#-telep√≠t√©s)
- [Haszn√°lat](#-haszn√°lat)
- [Template gy≈±jt√©s](#-template-gy≈±jt√©s)
- [Training](#-training)
- [Architekt√∫ra](#-architekt√∫ra)
- [Konfigur](#-konfiguration)

---

## ‚ú® Jellemz≈ëk

- **Deep Q-Network (DQN)** neur√°lis h√°l√≥
- **Pixel-based learning** - k√©perny≈ëb≈ël tanul
- **Reward shaping** - r√©szfeladatok jutalmaz√°sa
- **Template matching** - UI elemek felismer√©se
- **OCR t√°mogat√°s** - sz√∂veg/sz√°m kiolvas√°s
- **Tensorboard integr√°ci√≥** - training vizualiz√°ci√≥
- **Modular design** - k√∂nnyen b≈ëv√≠thet≈ë

---

## üîß Telep√≠t√©s

### 1. El≈ëfelt√©telek

- **Python 3.10+**
- **Tesseract OCR** ([let√∂lt√©s](https://github.com/UB-Mannheim/tesseract/wiki))
- **CUDA** (opcion√°lis, GPU gyors√≠t√°shoz)
- **BlueStacks** vagy m√°s Android emul√°tor

### 2. Repository kl√≥noz√°sa

```bash
git clone https://github.com/yourusername/rok-rl-agent.git
cd rok-rl-agent
```

### 3. Virtual environment l√©trehoz√°sa

```bash
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
```

### 4. Csomagok telep√≠t√©se

```bash
pip install -r requirements.txt
```

### 5. Tesseract be√°ll√≠t√°sa

Szerkeszd `config/settings.py`:
```python
TESSERACT_PATH = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
```

---

## üöÄ Haszn√°lat

### Gyors start (3 l√©p√©sben)

#### 1. Template k√©pek gy≈±jt√©se

```bash
python collect_templates.py
```

**Ezt kell csin√°lnod:**
1. Ind√≠tsd el a j√°t√©kot (BlueStacks)
2. Futtasd a scriptet
3. Jel√∂ld ki eg√©rrel a k√©rt UI elemeket
4. Nyomj ENTER-t minden ment√©shez

**Gy≈±jtend≈ë k√©pek:**

| Kateg√≥ria | Template | Le√≠r√°s |
|-----------|----------|--------|
| **Buildings** | `barracks_icon.png` | Barakk ikon |
| | `archery_icon.png` | √çj√°sz t√°bor ikon |
| | `stable_icon.png` | Ist√°ll√≥ ikon |
| | `siege_icon.png` | Ostromm≈±hely ikon |
| **UI** | `train_button.png` | "Train" gomb |
| | `zzzz_icon.png` | Foglalt queue ikon |
| | `confirm_button.png` | Meger≈ës√≠t√©s gomb |
| | `train_menu_header.png` | K√©pz√©s men√º fejl√©c |
| **Tiers** | `tier_t1.png` ... `tier_t5.png` | T1-T5 szint ikonok |

#### 2. Environment tesztel√©s

```bash
python test_environment.py
```

V√°laszd a **4. Interakt√≠v teszt** m√≥dot √©s pr√≥b√°lj ki n√©h√°ny akci√≥t.

#### 3. Training ind√≠t√°sa

```bash
python train.py --episodes 100
```

---

## üì∏ Template Gy≈±jt√©s - R√©szletes √∫tmutat√≥

### Automatikus m√≥dszer

```bash
python collect_templates.py
```

V√°laszd az **1. Template k√©pek gy≈±jt√©se** opci√≥t.

### Mi t√∂rt√©nik l√©p√©sr≈ël-l√©p√©sre:

1. **Ablak f√≥kusz**: Script automatikusan r√°keres a j√°t√©k ablakra
2. **Ter√ºletkijel√∂l√©s**: 
   - Bal eg√©rgombbal jel√∂ld ki a ter√ºletet
   - H√∫zd v√©gig az elemet (pl. Train gomb)
   - Nyomj **ENTER**-t a ment√©shez
3. **K√∂vetkez≈ë elem**: Automatikusan l√©p tov√°bb
4. **Befejez√©s**: √ñsszes template √∂sszegy≈±jtve

### Koordin√°t√°k gy≈±jt√©se (opcion√°lis)

```bash
python collect_templates.py
```

V√°laszd a **2. Koordin√°t√°k gy≈±jt√©se** opci√≥t, majd:
- Kattints a fontos pontokra (v√°ros k√∂z√©ppont, √©p√ºletek)
- √çrj be nevet minden koordin√°t√°hoz
- Nyomj **ESC**-et a befejez√©shez

Ment√©s helye: `templates/coordinates.json`

---

## üèãÔ∏è Training

### Alapvet≈ë training

```bash
python train.py
```

### Param√©terek

```bash
python train.py --episodes 500 --dueling
```

| Param√©ter | Le√≠r√°s | Default |
|-----------|--------|---------|
| `--episodes` | Epiz√≥dok sz√°ma | 1000 |
| `--dueling` | Dueling DQN haszn√°lata | False |
| `--resume` | Model folytat√°sa | None |

### Training folytat√°sa

```bash
python train.py --resume data/models/dqn_agent_ep100.pth
```

### Training monitoroz√°s

**Tensorboard** (TODO - k√©s≈ëbb implement√°lhat√≥):
```bash
tensorboard --logdir data/logs/tensorboard
```

**Log f√°jlok**:
- `data/logs/training_YYYYMMDD_HHMMSS.json`

**Grafikonok**:
- `data/models/training_plot_epXXX.png`

---

## üèóÔ∏è Architekt√∫ra

### F≈ë komponensek

```
rok-rl-agent/
‚îÇ
‚îú‚îÄ‚îÄ core/                    # Alapvet≈ë funkci√≥k
‚îÇ   ‚îú‚îÄ‚îÄ window_manager.py   # Ablakkezel√©s
‚îÇ   ‚îú‚îÄ‚îÄ image_manager.py    # K√©pfelismer√©s, OCR
‚îÇ   ‚îî‚îÄ‚îÄ action_executor.py  # Kattint√°sok
‚îÇ
‚îú‚îÄ‚îÄ environment/             # RL k√∂rnyezet
‚îÇ   ‚îú‚îÄ‚îÄ rok_env.py          # F≈ë environment
‚îÇ   ‚îî‚îÄ‚îÄ reward_manager.py   # Jutalom sz√°m√≠t√°s
‚îÇ
‚îú‚îÄ‚îÄ agent/                   # Neural network
‚îÇ   ‚îú‚îÄ‚îÄ network.py          # DQN architekt√∫ra
‚îÇ   ‚îú‚îÄ‚îÄ replay_buffer.py    # Experience replay
‚îÇ   ‚îî‚îÄ‚îÄ dqn_agent.py        # RL agent
‚îÇ
‚îî‚îÄ‚îÄ utils/                   # Seg√©dfunkci√≥k
    ‚îú‚îÄ‚îÄ logger.py
    ‚îî‚îÄ‚îÄ visualizer.py
```

### Neural Network

**DQN (Deep Q-Network)**:
- Input: 84x84x3 screenshot (RGB)
- 3x Convolutional layer
- 2x Fully connected layer
- Output: Q-values (20 akci√≥)

**Dueling DQN** (advanced):
- K√ºl√∂n Value √©s Advantage stream
- Jobb konvergencia

### Reward rendszer

| Esem√©ny | Reward | Detekt√°l√°s |
|---------|--------|------------|
| ‚úÖ K√©pz√©s elindult | +1.0 | Zzzz ikon megjelent |
| ‚úÖ Barakk megnyitva | +0.2 | Template match |
| ‚úÖ Train men√º nyitva | +0.2 | Tier ikonok |
| ‚úÖ Train gomb kattintva | +0.3 | Gomb elt≈±nt |
| ‚ùå Foglalt queue-ba pr√≥b√°lt | -1.0 | Zzzz l√°that√≥ |
| ‚ùå Felesleges kattint√°s | -0.1 | Nincs v√°ltoz√°s |
| ‚ùå Er≈ëforr√°s kifogyott | -0.5 | OCR |

---

## ‚öôÔ∏è Konfigur√°ci√≥

### settings.py m√≥dos√≠t√°sa

```python
# config/settings.py

# J√°t√©k ablak neve
GAME_WINDOW_TITLE = "BlueStacks App Player"  # V√°ltoztasd meg!

# Template matching pontoss√°g
TEMPLATE_MATCHING_THRESHOLD = 0.7  # 0.6-0.8 aj√°nlott

# Neural network
LEARNING_RATE = 0.0001
BATCH_SIZE = 32
MEMORY_SIZE = 10000

# Training
NUM_EPISODES = 1000
MAX_STEPS_PER_EPISODE = 500

# Exploration
EPSILON_START = 1.0    # 100% random kezdetben
EPSILON_END = 0.1      # 10% random v√©g√ºl
EPSILON_DECAY = 0.995
```

### Reward s√∫lyok m√≥dos√≠t√°sa

```python
REWARD_WEIGHTS = {
    'training_started': 1.0,      # F≈ê JUTALOM
    'barracks_opened': 0.2,       # Kisebb l√©p√©sek
    'wasted_click': -0.1,         # B√ºntet√©sek
}
```

---

## üêõ Hibakeres√©s

### Template nem tal√°lhat√≥

**Probl√©ma**: `‚ö†Ô∏è Template nem tal√°lhat√≥: ui/train_button.png`

**Megold√°s**:
1. Ellen≈ërizd hogy l√©tezik-e: `templates/ui/train_button.png`
2. Gy≈±jtsd √∫jra: `python collect_templates.py`
3. Cs√∂kkentsd a threshold-ot: `TEMPLATE_MATCHING_THRESHOLD = 0.6`

### Ablak nem tal√°lhat√≥

**Probl√©ma**: `‚ùå Nem tal√°lhat√≥ a j√°t√©k ablak!`

**Megold√°s**:
1. Ind√≠tsd el a j√°t√©kot
2. M√≥dos√≠tsd `GAME_WINDOW_TITLE` a `config/settings.py`-ben
3. Futtasd `test_environment.py` ‚Üí v√°lassz ablakot

### OCR nem m≈±k√∂dik

**Probl√©ma**: `‚ùå OCR hiba`

**Megold√°s**:
1. Telep√≠tsd Tesseract-ot
2. √Åll√≠tsd be `TESSERACT_PATH` √©rt√©k√©t
3. Teszteld: `pytesseract.get_tesseract_version()`

### GPU nem haszn√°l√≥dik

**Probl√©ma**: CPU-n fut (lass√∫)

**Megold√°s**:
```bash
# CUDA telep√≠t√©se ut√°n
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

---

## üìä Eredm√©nyek √©rtelmez√©se

### Training grafikonok

1. **Episode Rewards**: Javul-e az agent?
   - N√∂vekv≈ë trend = tanul ‚úÖ
   - Random = nem tanul ‚ùå

2. **Loss**: Neural network tanul√°s
   - Cs√∂kken≈ë = j√≥
   - Stabil ~0.1-0.5 = konverg√°lt

3. **Epsilon**: Exploration decay
   - 1.0 ‚Üí 0.1 fokozatos cs√∂kken√©s

4. **Cumulative Reward**: √ñsszteljes√≠tm√©ny
   - Pozit√≠v = j√≥ ir√°ny
   - Negat√≠v = rossz reward design

### Mikor sikeres a training?

‚úÖ **Sikeres tanul√°s jelei:**
- Episode reward n√∂vekszik
- Loss stabiliz√°l√≥dik
- Agent k√©pes k√©pz√©st elind√≠tani
- Nem pr√≥b√°l foglalt queue-ba k√©pezni

‚ùå **Probl√©m√°k:**
- Reward nem v√°ltozik ‚Üí Rossz reward design
- Loss n≈ë ‚Üí Learning rate t√∫l magas
- Random viselked√©s ‚Üí T√∫l kev√©s tapasztalat

---

## üîÆ Tov√°bbfejleszt√©si √∂tletek

- [ ] Multi-building support (t√∂bb √©p√ºlet p√°rhuzamosan)
- [ ] Resource management (er≈ëforr√°s gy≈±jt√©s)
- [ ] Building upgrades (fejleszt√©sek)
- [ ] Research (kutat√°sok)
- [ ] Commander management
- [ ] PvP strat√©gi√°k
- [ ] Prioritized Experience Replay
- [ ] Double DQN / Rainbow DQN
- [ ] Curriculum learning

---

## üìû T√°mogat√°s

**Probl√©m√°k eset√©n:**
1. Ellen≈ërizd `data/logs/` f√°jlokat
2. Futtasd `test_environment.py` diagnosztik√°t
3. Nyiss issue-t GitHub-on

---

## üìÑ Licenc

MIT License - szabadon haszn√°lhat√≥ √©s m√≥dos√≠that√≥

---

## üôè K√∂sz√∂netnyilv√°n√≠t√°s

- OpenAI Gym/Gymnasium inspir√°ci√≥
- DeepMind DQN paper
- Rise of Kingdoms j√°t√©k

---

**K√©sz√≠tette**: ROK RL Team  
**Verzi√≥**: 1.0.0  
**Utols√≥ friss√≠t√©s**: 2024

---

**J√≥ j√°t√©kot √©s sikeres tr√©ninget!** üöÄüéÆ